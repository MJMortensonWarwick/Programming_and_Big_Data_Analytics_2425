{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/s8/BPCXbbNZIl+SilBqn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MJMortensonWarwick/Programming_and_Big_Data_Analytics_2425/blob/main/2_03_Calculated_Fields%2C_Indexing_and_Subsetting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1vv_PsWBnUJwSCkwKDoJAC-vXjtaEA4Ts)"
      ],
      "metadata": {
        "id": "d8MkNWyHrNAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.03 Pandas: Calculated fields, indexing and subsetting dataframes\n",
        "### Calculated Fields\n",
        "In many forms of data analysis often we will want to generate new fields/columns based on existing data or as some combination of them. In other words, this is data that we are calculating rather than reading.\n",
        "\n",
        "We will create some calculated fields based on the dictionary input from the last session. If you have started a new notebook run the below code to recreate the dataframe:"
      ],
      "metadata": {
        "id": "2ZCfix169NXA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l17VXNTY8-eG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# create a dictionary of orders\n",
        "orders = {'o10001':{'date':'2025/01/10', 'product':'Blockchain database', 'quantity':'1'},\n",
        "            'o10002':{'date':'2025/01/13', 'product':'Stock market prediction engine', 'quantity':'2'},\n",
        "            'o10003':{'date':'2025/01/14', 'product':'Portfolio optimisation tool', 'quantity':'10'},\n",
        "            'o10004':{'date':'2025/01/15', 'product':'Man\\'s suit', 'quantity':'2'}\n",
        "}\n",
        "\n",
        "# convert to a dataframe\n",
        "orders_df = pd.DataFrame(orders)\n",
        "\n",
        "# create a dicitonary of products\n",
        "products = {'123':{'name':'Blockchain database', 'cost_price':12.12, 'sale_price':15.00},\n",
        "            '124':{'name':'Stock market prediction engine', 'cost_price':2.15, 'sale_price':9.99},\n",
        "            '125':{'name':'Portfolio optimisation tool', 'cost_price':22.45, 'sale_price':49.99},\n",
        "            '126':{'name':'Financial services chatbot', 'cost_price':0.45, 'sale_price':2.99},\n",
        "            '127':{'name':'Man\\'s suit', 'cost_price':0.78, 'sale_price':1.49}\n",
        "}\n",
        "\n",
        "# convert to a dataframe\n",
        "products_df = pd.DataFrame(products)\n",
        "\n",
        "# transpose (flip on their axes) both dataframes\n",
        "orders_df = orders_df.transpose()\n",
        "products_df = products_df.transpose()\n",
        "\n",
        "# join (left) orders_df and products_df\n",
        "joined_df = orders_df.merge(products_df, how='left', left_on='product', right_on='name')\n",
        "\n",
        "# drop the repeated column and display on screen\n",
        "joined_df = joined_df.drop(['name'], axis=1)\n",
        "joined_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expanding our example, we now want to know the total cost price and total sale price for each order, calculated by multiplying the unity prices by the quantity. Again, pandas makes this relatively easy to do â€¦ in theory at least. The following code would calculate, working much like a normal calculation on a single variable (as opposed to a whole column):"
      ],
      "metadata": {
        "id": "8EvGCLYP9hkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joined_df['total_cost_price'] = joined_df['quantity'] * joined_df['cost_price']\n",
        "joined_df['total_sale_price'] = joined_df['quantity'] * joined_df['sale_price']\n",
        "joined_df"
      ],
      "metadata": {
        "id": "RbQ3JF209q_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uh-oh ... error. More specifically the message \"TypeError: can't multiply sequence by non-int of type 'float'\". Although the description is a little technical, we can get the gist of the problem - there is some form of \"type\" error preventing the multiplication. Let's therefore evaluate what data types we have in our dataframe using a print statement:"
      ],
      "metadata": {
        "id": "nGshIPYf9zht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(joined_df.dtypes)"
      ],
      "metadata": {
        "id": "hPKxg9Xi90RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We would want our quantity, cost_price and sale_price to be of a numeric type (float or integer). In this case everything is listed as an \"object\". Object is pandas' most flexible data type (dtype) designed to work with \"text or mixed numeric and non-numeric values\". While pandas will try to infer the relevant type for data, the fallback option is to assign as object which is what has happened here. However, we can fix this fairly easily with a for loop that converts the relevant fields to floats. An alternative approach, particularly when you have many columns of data, is to ask pandas to convert them as a set using convert_dtypes (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.convert_dtypes.html)."
      ],
      "metadata": {
        "id": "pC_9-Brz95-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "field_list = ['quantity', 'cost_price', 'sale_price']\n",
        "for field in field_list:\n",
        "    joined_df[field] = joined_df[field].astype(float)"
      ],
      "metadata": {
        "id": "75zsQ7S696zY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To explain what we are doing here.\n",
        "1. First, we have created a list of the fields (columns) we want to change ('quantity', 'cost_price' and 'sale_price') called field_list.\n",
        "2. Secondly we have created a __for__ loop that iterates through this list.\n",
        "3. For each of the records in _joined\\_df_ we index (you\\'ll see this below) the dataframe by that particular field. I.e. we'll find that particular field.\n",
        "4. Lastly, we change the __type__ of that dataitem from \"object\" (i.e. a __string__) to \"float\" (i.e. a decimal number).\n",
        "\n",
        "With this in place we can run the earlier code without error:"
      ],
      "metadata": {
        "id": "n7lc2e9U9-5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joined_df['total_cost_price'] = joined_df['quantity'] * joined_df['cost_price']\n",
        "joined_df['total_sale_price'] = joined_df['quantity'] * joined_df['sale_price']\n",
        "joined_df"
      ],
      "metadata": {
        "id": "HI8IscfM-C9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indexing and Subsetting Dataframes\n",
        "As with strings and lists, we can index/slice pandas dataframes based on a range of criteria. Note, this is an area where the recommended pandas syntax has changed significantly over the years. In the past .ix (index) was the preferred syntax, and you will still often see this in older libraries/tutorials. Today, however, _.loc_ (location) and _.iloc_ (index location) are the prefered options and the ones we will use here. We will start by indexing item zero (the first item) in our dataframe:"
      ],
      "metadata": {
        "id": "GcQqn9QK-O5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joined_df.iloc[0]"
      ],
      "metadata": {
        "id": "iTYXQWK9-aVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although the command is slightly different than when working with strings and lists, the principles remain the same, and it is also possible to use slices here by including a colon:"
      ],
      "metadata": {
        "id": "5iBPYG1l-gsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joined_df.iloc[0:2]"
      ],
      "metadata": {
        "id": "Dl91zKfr-ke9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can view specific columns by calling them by name. Note, we used this feature in our earlier for loop to change dtypes."
      ],
      "metadata": {
        "id": "OivB2WAL-vE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joined_df['product']"
      ],
      "metadata": {
        "id": "bxyOyRkQ-yJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The same techniques can also be used to create subsets of the data:"
      ],
      "metadata": {
        "id": "i0GGyaRy_Ahc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset_one = joined_df.iloc[0:2]\n",
        "df_subset_one"
      ],
      "metadata": {
        "id": "NDsiCYeL_A_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset_two = joined_df[['product', 'quantity', 'total_sale_price']]\n",
        "df_subset_two"
      ],
      "metadata": {
        "id": "yts3jTvg_IQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that subsetting by rows follows the normal Python convention where the first number is the first item to return and the second is the value after the last item to return. Subsetting by columns requires a double set of square brackets (e.g. [['a', 'b', 'c']])."
      ],
      "metadata": {
        "id": "nqi47nit_Fu2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exporting Dataframes\n",
        "Finally, we can use Pandas to efficiently export our Dataframe to file. There are multiple export options available, see the documentation for more details: https://pandas.pydata.org/pandas-docs/stable/reference/frame.html#conversion, to include Excel, many major databases, and even HTML. However, typically the most useful is to CSV (for reusability):"
      ],
      "metadata": {
        "id": "8KOKLEXE_SHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joined_df.to_csv('Joined_Dataframe.csv', sep=\",\")"
      ],
      "metadata": {
        "id": "1_bDkcWv_XHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the sep=\",\" denotes that the columns will be sepearated by a comma - hence the file type CSV (Comma Separated Values). Click on the folder icon on the left to download and check your file."
      ],
      "metadata": {
        "id": "TLkJoGGP_Yo_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXERCISES\n",
        "1. Using _product\\_df_, can you create a calculated field for the amount of markup associated with each product? The formula for this should be:\n",
        "$markup = \\frac{(sale \\hspace{0.1cm} price \\hspace{0.2cm} - \\hspace{0.2cm} cost \\hspace{0.2cm} price)}{cost \\hspace{0.1cm} price}$\n",
        "\n",
        "2. Can you also create a calculated field for the percentage markup?\n",
        "\n",
        "3. Working this time with _joined\\_df_, can you create a subset of the dataframe where the total sale price is less than Â£20.00?"
      ],
      "metadata": {
        "id": "SVnPo3Q5_pGd"
      }
    }
  ]
}